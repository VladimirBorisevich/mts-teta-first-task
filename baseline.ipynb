{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Построение бейзлайн модели является довольно важным моментом, так как именно ориентируясь на бейзлайн и будет происходить дальнейшие изменения.   \n",
    "В нашем случае будет предсказываться стоимость жилья в зависимости от его параметров (площадь, количество комнат, геопозиция, регион и тд)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"all_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> С помощью EDA было выяснено, что в датасете содержатся некорректны данные, а также большое количество выбросов.  </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Проведем чистку данных. Чтобы убрать ошибочные значения, которые в дальнейшем могут ухудшить качество модели. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.price > 0)&(data.rooms!=-2)&(data.area>0)&(data.kitchen_area>0)]\n",
    "data = data.drop_duplicates()\n",
    "data.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Уберем регионы, у которых очень мало значений. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_to_drop = data.groupby('region')['region'].count().sort_values().head(40).index.to_list()\n",
    "rows_to_drop = np.array([])\n",
    "for region in regions_to_drop:\n",
    "    rows_to_drop = np.append(rows_to_drop,np.where(data.region==region)[0])\n",
    "data.drop(rows_to_drop,axis=0,inplace=True)\n",
    "data.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Функция для чистки данных от выбросов. Функия убирает из датасета строки с экстремальными значениями  (более или менее 3х среднеквадратичных отклонений) для каждого региона. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_by_region(data,feature,region):\n",
    "        std_shift_3 = data.loc[data.region==region][feature].std() * 3\n",
    "        feat_mean = data.loc[data.region==region][feature].mean()\n",
    "        lower_bound = feat_mean-std_shift_3\n",
    "        upper_bound = feat_mean+std_shift_3\n",
    "        rows_to_drop = np.where((data.loc[data.region==region,feature]<lower_bound) | \\\n",
    "                                (data.loc[data.region==region,feature]>=upper_bound))[0]\n",
    "        indexes = data.loc[data.region==region].iloc[rows_to_drop].index\n",
    "        data.drop(indexes,axis=0,inplace=True)\n",
    "        data.reset_index(inplace=True,drop=True)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [01:00<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "for region in tqdm(data.region.unique()):\n",
    "    data = norm_by_region(data,\"price\",region)\n",
    "    data = norm_by_region(data,\"area\",region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Преобразуем даты в целое число дней с момента начала данных, для того чтобы привести признаковые описания к одному виду. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"date_time\"] = data[\"date\"] + \" \" + data[\"time\"]\n",
    "data = data.drop([\"date\",\"time\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date_time'] = pd.to_datetime(data[\"date_time\"])\n",
    "data[\"day_delta\"] = (data[\"date_time\"] - data.date_time.min()).dt.days\n",
    "data = data.drop(\"date_time\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Преобразуем бинарный признак. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"object_type\"] = data[\"object_type\"].map({1:0,11:1}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> One hot encoding для категориальных признаков. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_types = pd.get_dummies(data[\"building_type\"],prefix=\"buiilding_type_\")\n",
    "regions = pd.get_dummies(data[\"region\"],prefix=\"region_\")\n",
    "data = data.drop(\"building_type\",axis=1)\n",
    "data = data.drop(\"region\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Делим выборку на обучающую и тестовую с учетом временного ряда, в соотношении 70/30. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by=\"day_delta\")\n",
    "train = data.iloc[:round(data.shape[0]*0.7)]\n",
    "test = data.iloc[round(data.shape[0]*0.7):]\n",
    "y_train = train.price\n",
    "y_test = test.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"price\",axis=1)\n",
    "test = test.drop(\"price\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Проведем нормализацию данных для того,чтобы исключить дисбаланс между значениями признаков и привести их к одному порядку. Это положительно отразится на устойчивости работы модели. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Присоединяем категориальные фичи после скалирования выборок. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = np.hstack((train_scaled,building_types.values[:round(data.shape[0]*0.7)]))\n",
    "train_scaled = np.hstack((train_scaled,regions.values[:round(data.shape[0]*0.7)]))\n",
    "test_scaled = np.hstack((test_scaled,building_types.values[round(data.shape[0]*0.7):]))\n",
    "test_scaled = np.hstack((test_scaled,regions.values[round(data.shape[0]*0.7):]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Построим baseline модель, чтобы в дальнейшем анализировать прирост качества в зависимости с усложнением моделей. В качестве метрики используем среднее абсолютное отклонение (mean absolute error (MAE)). Метрика довольно легко рассчитывается, и она наглядна. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.9 s, sys: 1.8 s, total: 43.7 s\n",
      "Wall time: 15.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "linear = LinearRegression()\n",
    "linear.fit(train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2044101.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(mean_absolute_error(y_test,linear.predict(test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1549607.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(mean_absolute_error(y_train,linear.predict(train_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Проверим как изменится качество при использовании более сложной модели.  \n",
    "Более сложная модель машинного обучения показывает лучше результат, однако время обучения и прогноза возрастает. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.9 s, sys: 563 ms, total: 46.5 s\n",
      "Wall time: 6.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lgb = LGBMRegressor()\n",
    "lgb.fit(train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1040824.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(mean_absolute_error(y_test, lgb.predict(test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "648948.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(mean_absolute_error(y_train, lgb.predict(train_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Линейная регрессия может выступать в качестве бейзлайна. Модель относительно простая и её легко объяснить. Сравнивая её с градиентным бустингом точность модели ниже, но она превосходит в скорости обучения и прогнозирования. Признаковые преобразования и чистка данных от выбросов может значительно увеличить её качество (а также подбор гиперпараметров).  </b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
